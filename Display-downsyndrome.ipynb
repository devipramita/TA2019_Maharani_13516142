{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Images marked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark frontal face image automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[180., 136.],\n",
       "       [183., 163.],\n",
       "       [188., 188.],\n",
       "       [193., 214.],\n",
       "       [201., 240.],\n",
       "       [214., 264.],\n",
       "       [233., 285.],\n",
       "       [255., 301.],\n",
       "       [281., 306.],\n",
       "       [310., 302.],\n",
       "       [339., 288.],\n",
       "       [366., 270.],\n",
       "       [386., 247.],\n",
       "       [400., 221.],\n",
       "       [409., 192.],\n",
       "       [416., 163.],\n",
       "       [420., 132.],\n",
       "       [191., 128.],\n",
       "       [204., 115.],\n",
       "       [224., 113.],\n",
       "       [243., 117.],\n",
       "       [263., 123.],\n",
       "       [297., 121.],\n",
       "       [319., 114.],\n",
       "       [341., 109.],\n",
       "       [364., 113.],\n",
       "       [382., 126.],\n",
       "       [279., 144.],\n",
       "       [278., 157.],\n",
       "       [277., 170.],\n",
       "       [276., 184.],\n",
       "       [262., 203.],\n",
       "       [269., 205.],\n",
       "       [277., 206.],\n",
       "       [286., 205.],\n",
       "       [296., 203.],\n",
       "       [217., 145.],\n",
       "       [229., 137.],\n",
       "       [244., 137.],\n",
       "       [255., 151.],\n",
       "       [243., 156.],\n",
       "       [227., 155.],\n",
       "       [313., 151.],\n",
       "       [324., 137.],\n",
       "       [340., 137.],\n",
       "       [353., 145.],\n",
       "       [342., 154.],\n",
       "       [326., 155.],\n",
       "       [251., 244.],\n",
       "       [260., 235.],\n",
       "       [270., 228.],\n",
       "       [276., 231.],\n",
       "       [284., 229.],\n",
       "       [298., 237.],\n",
       "       [313., 246.],\n",
       "       [299., 259.],\n",
       "       [285., 263.],\n",
       "       [277., 263.],\n",
       "       [270., 262.],\n",
       "       [260., 256.],\n",
       "       [258., 244.],\n",
       "       [270., 240.],\n",
       "       [277., 240.],\n",
       "       [284., 240.],\n",
       "       [305., 246.],\n",
       "       [284., 247.],\n",
       "       [277., 247.],\n",
       "       [270., 245.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append('..')\n",
    "from assist import marker\n",
    "\n",
    "# marker.frontal_face_marker(r'..\\data\\00019fa010_940128.tif')\n",
    "marker.frontal_face_marker(r'..\\data\\downsyndrome1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change landmarks through dragging (if not satisfied with the auto-marking result)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marker.mark_modifier(r'..\\data\\00019fa010_940128.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark profile image manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marker.manual_marker(r'..\\data\\00019pr010_940128.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start 3D fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml\n",
    "from core import Blendshape, contour_correspondence, EdgeTopology, fitting, LandmarkMapper, Landmark, MorphableModel, \\\n",
    "    utils, RenderingParameters, render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\core\\orthographic_camera_estimation_linear.py:83: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  k = np.linalg.lstsq(a, b)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile-yaw: -52.512013779756295\n",
      "profile-pitch: -68.78926301729987\n",
      "profile-roll: 105.5092249680388\n",
      "96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\core\\linear_shape_fitting.py:257: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  c_s = np.linalg.lstsq(at_omega_reg, rhs)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.778637912438974\n",
      "loop 1 is finished at time: 0.27101993560791016\n",
      "profile-yaw: -52.399488790504684\n",
      "profile-pitch: -70.32741885957456\n",
      "profile-roll: 107.14271189942087\n",
      "11.744294725619401\n",
      "loop 2 is finished at time: 0.3010225296020508\n",
      "profile-yaw: -54.98918206753711\n",
      "profile-pitch: -77.17236248898465\n",
      "profile-roll: 111.79625025770875\n",
      "7.897750690188776\n",
      "loop 3 is finished at time: 0.3460257053375244\n",
      "profile-yaw: -55.8487859049014\n",
      "profile-pitch: -84.29094520667036\n",
      "profile-roll: 118.63451534657302\n",
      "2.635005993938337\n",
      "loop 4 is finished at time: 0.38902926445007324\n",
      "profile-yaw: -55.8487859049014\n",
      "profile-pitch: -84.29094520667036\n",
      "profile-roll: 118.63451534657302\n",
      "1.4026558048804263\n",
      "loop 5 is finished at time: 0.43203186988830566\n",
      "profile-yaw: -55.8487859049014\n",
      "profile-pitch: -84.29094520667036\n",
      "profile-roll: 118.63451534657302\n",
      "1.105232951230468\n",
      "loop 6 is finished at time: 0.4840376377105713\n",
      "profile-yaw: -55.8487859049014\n",
      "profile-pitch: -84.29094520667036\n",
      "profile-roll: 118.63451534657302\n",
      "0.6646918878726269\n",
      "loop 7 is finished at time: 0.5310392379760742\n",
      "profile-yaw: -55.8487859049014\n",
      "profile-pitch: -84.29094520667036\n",
      "profile-roll: 118.63451534657302\n",
      "0.5523379718096668\n",
      "loop 8 is finished at time: 0.576042652130127\n",
      "profile-yaw: -55.8487859049014\n",
      "profile-pitch: -84.29094520667036\n",
      "profile-roll: 118.63451534657302\n",
      "0.46174114914305237\n",
      "loop 9 is finished at time: 0.6220464706420898\n",
      "profile-yaw: -55.8487859049014\n",
      "profile-pitch: -84.29094520667036\n",
      "profile-roll: 118.63451534657302\n",
      "0.3874475436067039\n",
      "loop 10 is finished at time: 0.6720521450042725\n",
      "--- 2.211228132247925 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "frontal_pic_name = 'downsyndrome1'\n",
    "profile_pic_name = 'downsyndrome1'\n",
    "frontal_img = cv2.imread(os.path.join(r'..\\data', frontal_pic_name + '.png'))\n",
    "profile_img = cv2.imread(os.path.join(r'..\\data', profile_pic_name + '.png'))\n",
    "width = np.shape(frontal_img)[1]\n",
    "height = np.shape(frontal_img)[0]\n",
    "\n",
    "s = 2000 / height if height >= width else 2000 / width\n",
    "scale_param = 900 / height if height >= width else 900 / width\n",
    "\n",
    "morphable_model = MorphableModel.load_model(r\"..\\py_share\\py_sfm_shape_3448.bin\")\n",
    "blendshapes = Blendshape.load_blendshapes(r\"..\\py_share\\py_expression_blendshapes_3448.bin\")\n",
    "landmark_mapper = LandmarkMapper.LandmarkMapper(r'..\\py_share\\ibug_to_sfm.txt')\n",
    "edge_topology = EdgeTopology.load_edge_topology(r'..\\py_share\\py_sfm_3448_edge_topology.json')\n",
    "contour_landmarks = contour_correspondence.ContourLandmarks()\n",
    "contour_landmarks.load(r'..\\py_share\\ibug_to_sfm.txt')\n",
    "model_contour = contour_correspondence.ModelContour()\n",
    "model_contour.load(r'..\\py_share\\sfm_model_contours.json')\n",
    "profile_landmark_mapper = LandmarkMapper.ProfileLandmarkMapper(r'..\\py_share\\profile_to_sfm.txt')\n",
    "\n",
    "frontal_landmarks = []\n",
    "landmark_ids = list(map(str, range(1, 69)))  # generates the numbers 1 to 68, as strings\n",
    "landmarks = utils.read_pts(os.path.join(r'..\\data', frontal_pic_name + '.pts'))\n",
    "for i in range(68):\n",
    "    frontal_landmarks.append(Landmark.Landmark(landmark_ids[i], [landmarks[i][0] * s, landmarks[i][1] * s]))\n",
    "\n",
    "profile_landmarks = []\n",
    "landmarks = utils.read_pts(os.path.join(r'..\\data', profile_pic_name + '.pts'))\n",
    "for x in profile_landmark_mapper.right_mapper.keys():\n",
    "    coor = landmarks[int(x) - 1]\n",
    "    profile_landmarks.append(Landmark.Landmark(x, [coor[0] * s, coor[1] * s]))\n",
    "\n",
    "py_mesh, frontal_rendering_params, profile_rendering_params = fitting.fit_front_and_profile(\n",
    "    morphable_model, blendshapes, frontal_landmarks, landmark_mapper, profile_landmarks, profile_landmark_mapper,\n",
    "    round(width * s), round(height * s), edge_topology, contour_landmarks, model_contour, lambda_p=20,\n",
    "    num_iterations=10)\n",
    "\n",
    "profile_img = cv2.resize(profile_img, (round(width * scale_param), round(height * scale_param)),\n",
    "                         interpolation=cv2.INTER_CUBIC)\n",
    "render.draw_wireframe_with_depth(\n",
    "    profile_img, py_mesh, profile_rendering_params.get_modelview(), profile_rendering_params.get_projection(),\n",
    "    RenderingParameters.get_opencv_viewport(width * s, height * s), profile_landmark_mapper, scale_param / s)\n",
    "\n",
    "frontal_img = cv2.resize(frontal_img, (round(width * scale_param), round(height * scale_param)),\n",
    "                         interpolation=cv2.INTER_CUBIC)\n",
    "render.draw_wireframe_with_depth(\n",
    "    frontal_img, py_mesh, frontal_rendering_params.get_modelview(), frontal_rendering_params.get_projection(),\n",
    "    RenderingParameters.get_opencv_viewport(width * s, height * s), landmark_mapper, scale_param / s)\n",
    "\n",
    "for lm in frontal_landmarks:\n",
    "    cv2.rectangle(\n",
    "        frontal_img, (int(lm.coordinates[0] * scale_param / s) - 2, int(lm.coordinates[1] * scale_param / s) - 2),\n",
    "        (int(lm.coordinates[0] * scale_param / s) + 2, int(lm.coordinates[1] * scale_param / s) + 2), (255, 0, 0))\n",
    "\n",
    "for lm in profile_landmarks:\n",
    "    cv2.rectangle(\n",
    "        profile_img, (int(lm.coordinates[0] * scale_param / s) - 2, int(lm.coordinates[1] * scale_param / s) - 2),\n",
    "        (int(lm.coordinates[0] * scale_param / s) + 2, int(lm.coordinates[1] * scale_param / s) + 2), (255, 0, 0))\n",
    "    \n",
    "img = np.hstack([frontal_img, profile_img])\n",
    "\n",
    "# cv2.imshow(\"Image\", img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and rescale pictures and landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontal_pic_name = 'downsyndrome1'\n",
    "profile_pic_name = 'downsyndrome1'\n",
    "frontal_img = cv2.imread(os.path.join(r'..\\data', frontal_pic_name + '.png'))\n",
    "profile_img = cv2.imread(os.path.join(r'..\\data', profile_pic_name + '.png'))\n",
    "width = np.shape(frontal_img)[1]\n",
    "height = np.shape(frontal_img)[0]\n",
    "\n",
    "s = 2000 / height if height >= width else 2000 / width\n",
    "scale_param = 900 / height if height >= width else 900 / width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphable_model = MorphableModel.load_model(r\"..\\py_share\\py_sfm_shape_3448.bin\")\n",
    "blendshapes = Blendshape.load_blendshapes(r\"..\\py_share\\py_expression_blendshapes_3448.bin\")\n",
    "landmark_mapper = LandmarkMapper.LandmarkMapper(r'..\\py_share\\ibug_to_sfm.txt')\n",
    "edge_topology = EdgeTopology.load_edge_topology(r'..\\py_share\\py_sfm_3448_edge_topology.json')\n",
    "contour_landmarks = contour_correspondence.ContourLandmarks()\n",
    "contour_landmarks.load(r'..\\py_share\\ibug_to_sfm.txt')\n",
    "model_contour = contour_correspondence.ModelContour()\n",
    "model_contour.load(r'..\\py_share\\sfm_model_contours.json')\n",
    "profile_landmark_mapper = LandmarkMapper.ProfileLandmarkMapper(r'..\\py_share\\profile_to_sfm.txt')\n",
    "\n",
    "frontal_landmarks = []\n",
    "landmark_ids = list(map(str, range(1, 69)))  # generates the numbers 1 to 68, as strings\n",
    "landmarks = utils.read_pts(os.path.join(r'..\\data', frontal_pic_name + '.pts'))\n",
    "for i in range(68):\n",
    "    frontal_landmarks.append(Landmark.Landmark(landmark_ids[i], [landmarks[i][0] * s, landmarks[i][1] * s]))\n",
    "\n",
    "profile_landmarks = []\n",
    "landmarks = utils.read_pts(os.path.join(r'..\\data', profile_pic_name + '.pts'))\n",
    "for x in profile_landmark_mapper.right_mapper.keys():\n",
    "    coor = landmarks[int(x) - 1]\n",
    "    profile_landmarks.append(Landmark.Landmark(x, [coor[0] * s, coor[1] * s]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\core\\orthographic_camera_estimation_linear.py:83: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  k = np.linalg.lstsq(a, b)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile-yaw: -52.512013779756295\n",
      "profile-pitch: -68.78926301729987\n",
      "profile-roll: 105.5092249680388\n",
      "96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\core\\linear_shape_fitting.py:257: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  c_s = np.linalg.lstsq(at_omega_reg, rhs)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.778637912438974\n",
      "loop 1 is finished at time: 0.6986696720123291\n",
      "profile-yaw: -52.399488790504684\n",
      "profile-pitch: -70.32741885957456\n",
      "profile-roll: 107.14271189942087\n",
      "11.744294725619401\n",
      "loop 2 is finished at time: 0.7266721725463867\n",
      "profile-yaw: -54.98918206753711\n",
      "profile-pitch: -77.17236248898465\n",
      "profile-roll: 111.79625025770875\n",
      "7.897750690188776\n",
      "loop 3 is finished at time: 0.7716763019561768\n",
      "profile-yaw: -55.8487859049014\n",
      "profile-pitch: -84.29094520667036\n",
      "profile-roll: 118.63451534657302\n",
      "2.635005993938337\n",
      "loop 4 is finished at time: 0.8216793537139893\n",
      "profile-yaw: -55.8487859049014\n",
      "profile-pitch: -84.29094520667036\n",
      "profile-roll: 118.63451534657302\n",
      "1.4026558048804263\n",
      "loop 5 is finished at time: 0.8696849346160889\n",
      "profile-yaw: -55.8487859049014\n",
      "profile-pitch: -84.29094520667036\n",
      "profile-roll: 118.63451534657302\n",
      "1.105232951230468\n",
      "loop 6 is finished at time: 0.9216902256011963\n",
      "profile-yaw: -55.8487859049014\n",
      "profile-pitch: -84.29094520667036\n",
      "profile-roll: 118.63451534657302\n",
      "0.6646918878726269\n",
      "loop 7 is finished at time: 0.9727053642272949\n",
      "profile-yaw: -55.8487859049014\n",
      "profile-pitch: -84.29094520667036\n",
      "profile-roll: 118.63451534657302\n",
      "0.5523379718096668\n",
      "loop 8 is finished at time: 1.0216939449310303\n",
      "profile-yaw: -55.8487859049014\n",
      "profile-pitch: -84.29094520667036\n",
      "profile-roll: 118.63451534657302\n",
      "0.46174114914305237\n",
      "loop 9 is finished at time: 1.0686984062194824\n",
      "profile-yaw: -55.8487859049014\n",
      "profile-pitch: -84.29094520667036\n",
      "profile-roll: 118.63451534657302\n",
      "0.3874475436067039\n",
      "loop 10 is finished at time: 1.1217014789581299\n",
      "--- 1.1227030754089355 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "py_mesh, frontal_rendering_params, profile_rendering_params = fitting.fit_front_and_profile(\n",
    "    morphable_model, blendshapes, frontal_landmarks, landmark_mapper, profile_landmarks, profile_landmark_mapper,\n",
    "    round(width * s), round(height * s), edge_topology, contour_landmarks, model_contour, lambda_p=20,\n",
    "    num_iterations=10)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize fitting result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_img = cv2.resize(profile_img, (round(width * scale_param), round(height * scale_param)),\n",
    "                         interpolation=cv2.INTER_CUBIC)\n",
    "render.draw_wireframe_with_depth(\n",
    "    profile_img, py_mesh, profile_rendering_params.get_modelview(), profile_rendering_params.get_projection(),\n",
    "    RenderingParameters.get_opencv_viewport(width * s, height * s), profile_landmark_mapper, scale_param / s)\n",
    "\n",
    "frontal_img = cv2.resize(frontal_img, (round(width * scale_param), round(height * scale_param)),\n",
    "                         interpolation=cv2.INTER_CUBIC)\n",
    "render.draw_wireframe_with_depth(\n",
    "    frontal_img, py_mesh, frontal_rendering_params.get_modelview(), frontal_rendering_params.get_projection(),\n",
    "    RenderingParameters.get_opencv_viewport(width * s, height * s), landmark_mapper, scale_param / s)\n",
    "\n",
    "for lm in frontal_landmarks:\n",
    "    cv2.rectangle(\n",
    "        frontal_img, (int(lm.coordinates[0] * scale_param / s) - 2, int(lm.coordinates[1] * scale_param / s) - 2),\n",
    "        (int(lm.coordinates[0] * scale_param / s) + 2, int(lm.coordinates[1] * scale_param / s) + 2), (255, 0, 0))\n",
    "\n",
    "for lm in profile_landmarks:\n",
    "    cv2.rectangle(\n",
    "        profile_img, (int(lm.coordinates[0] * scale_param / s) - 2, int(lm.coordinates[1] * scale_param / s) - 2),\n",
    "        (int(lm.coordinates[0] * scale_param / s) + 2, int(lm.coordinates[1] * scale_param / s) + 2), (255, 0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show fitting result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.hstack([frontal_img, profile_img])\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save result and fitted 3D model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downsyndrome1-output\n"
     ]
    }
   ],
   "source": [
    "cv2.imwrite(frontal_pic_name + '-outcome.jpg', img)\n",
    "render.save_ply(py_mesh, frontal_pic_name + '-output', [210, 183, 108], author='Yinghao Li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
